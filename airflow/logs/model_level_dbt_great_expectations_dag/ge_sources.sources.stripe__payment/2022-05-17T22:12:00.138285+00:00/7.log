[2022-05-18 22:25:06,977] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: model_level_dbt_great_expectations_dag.ge_sources.sources.stripe__payment scheduled__2022-05-17T22:12:00.138285+00:00 [queued]>
[2022-05-18 22:25:07,002] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: model_level_dbt_great_expectations_dag.ge_sources.sources.stripe__payment scheduled__2022-05-17T22:12:00.138285+00:00 [queued]>
[2022-05-18 22:25:07,003] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-18 22:25:07,005] {taskinstance.py:1242} INFO - Starting attempt 7 of 10
[2022-05-18 22:25:07,006] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-18 22:25:07,029] {taskinstance.py:1262} INFO - Executing <Task(GreatExpectationsOperator): ge_sources.sources.stripe__payment> on 2022-05-17 22:12:00.138285+00:00
[2022-05-18 22:25:07,043] {standard_task_runner.py:52} INFO - Started process 166 to run task
[2022-05-18 22:25:07,055] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'model_level_dbt_great_expectations_dag', 'ge_sources.sources.stripe__payment', 'scheduled__2022-05-17T22:12:00.138285+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/model_level_dbt_great_expectations_dag.py', '--cfg-path', '/tmp/tmpmjrfr1s1', '--error-file', '/tmp/tmp2p1ixamz']
[2022-05-18 22:25:07,056] {standard_task_runner.py:77} INFO - Job 55: Subtask ge_sources.sources.stripe__payment
[2022-05-18 22:25:07,177] {logging_mixin.py:109} INFO - Running <TaskInstance: model_level_dbt_great_expectations_dag.ge_sources.sources.stripe__payment scheduled__2022-05-17T22:12:00.138285+00:00 [running]> on host 2c85119e8615
[2022-05-18 22:25:07,775] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=luciano.naveiro
AIRFLOW_CTX_DAG_ID=model_level_dbt_great_expectations_dag
AIRFLOW_CTX_TASK_ID=ge_sources.sources.stripe__payment
AIRFLOW_CTX_EXECUTION_DATE=2022-05-17T22:12:00.138285+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-17T22:12:00.138285+00:00
[2022-05-18 22:25:07,779] {great_expectations.py:122} INFO - Running validation with Great Expectations...
[2022-05-18 22:25:07,787] {great_expectations.py:125} INFO - Ensuring data context is valid...
[2022-05-18 22:25:13,144] {sqlalchemy_execution_engine.py:404} WARNING - schema_name specified creating a URL with schema is not supported. Set a default schema on the user connecting to your database.
[2022-05-18 22:25:13,396] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/great_expectations/datasource/data_connector/runtime_data_connector.py:135 DeprecationWarning: Specifying batch_identifiers as part of the RuntimeDataConnector config is deprecated as of v0.15.1 and will be removed by v0.18. Please configure batch_identifiers as part of Assets instead.
[2022-05-18 22:25:13,406] {base_data_context.py:474} WARNING - Cannot initialize datasource jaffle_shop: Cannot initialize datasource jaffle_shop, error: (psycopg2.OperationalError) could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-05-18 22:25:17,468] {taskinstance.py:1703} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations_provider/operators/great_expectations.py", line 160, in execute
    result = self.checkpoint.run()
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 287, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/checkpoint/checkpoint.py", line 168, in run
    validation_dict=validation_dict,
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/checkpoint/checkpoint.py", line 320, in _run_validation
    else None
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/data_context/data_context/base_data_context.py", line 1872, in get_validator
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 287, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/data_context/data_context/base_data_context.py", line 1757, in get_batch_list
    "The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate.",
great_expectations.exceptions.exceptions.DatasourceError: Cannot initialize datasource jaffle_shop, error: The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate.
[2022-05-18 22:25:17,542] {taskinstance.py:1280} INFO - Marking task as UP_FOR_RETRY. dag_id=model_level_dbt_great_expectations_dag, task_id=ge_sources.sources.stripe__payment, execution_date=20220517T221200, start_date=20220518T222506, end_date=20220518T222517
[2022-05-18 22:25:17,579] {standard_task_runner.py:91} ERROR - Failed to execute job 55 for task ge_sources.sources.stripe__payment
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations_provider/operators/great_expectations.py", line 160, in execute
    result = self.checkpoint.run()
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 287, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/checkpoint/checkpoint.py", line 168, in run
    validation_dict=validation_dict,
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/checkpoint/checkpoint.py", line 320, in _run_validation
    else None
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/data_context/data_context/base_data_context.py", line 1872, in get_validator
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 287, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/great_expectations/data_context/data_context/base_data_context.py", line 1757, in get_batch_list
    "The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate.",
great_expectations.exceptions.exceptions.DatasourceError: Cannot initialize datasource jaffle_shop, error: The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate.
[2022-05-18 22:25:17,706] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-18 22:25:17,822] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
